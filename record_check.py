import streamlit as st
import pandas as pd
import re
from collections import Counter
import html 

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
.error-highlight {
    color: red;
    font-weight: bold;
    background-color: #ffe0e0;
    padding: 2px 4px;
    border-radius: 4px;
}
.sentence-error-highlight {
    color: #0056b3; /* ì–´ë‘ìš´ íŒŒë€ìƒ‰ */
    font-weight: bold;
    background-color: #e0f0ff; /* ë°ì€ íŒŒë€ìƒ‰ */
    padding: 2px 4px;
    border-radius: 4px;
}
</style>
""", unsafe_allow_html=True)

# --- ì˜¤ë¥˜ ê²€ì‚¬ í•¨ìˆ˜ ---

def find_regex_errors(text, patterns):
    """ì •ê·œì‹ íŒ¨í„´ì— ë§ëŠ” ì˜¤ë¥˜ë¥¼ ì°¾ì•„ (start, end) ì¸ë±ìŠ¤ì™€ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜"""
    errors_found = []
    all_matches = [] # (start, end) íŠœí”Œ ì €ì¥

    # 1. ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ì˜¤ë¥˜ ìœ„ì¹˜ ì°¾ê¸°
    for error_type, pattern, message in patterns:
        # re.IGNORECASE: ì˜ì–´ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ì‚¬
        for match in re.finditer(pattern, text, re.IGNORECASE):
            all_matches.append((match.start(), match.end()))
            if message not in errors_found:
                errors_found.append(message)
    
    return all_matches, list(set(errors_found)) # ì¤‘ë³µ ì œê±°

def apply_merged_highlights(text, red_matches, blue_matches):
    """
    ë¹¨ê°„ìƒ‰(ë‹¨ì–´)ê³¼ íŒŒë€ìƒ‰(ë¬¸ì¥) í•˜ì´ë¼ì´íŠ¸ ìœ„ì¹˜ë¥¼ ë°›ì•„ HTML íƒœê·¸ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    ê²¹ì¹˜ëŠ” êµ¬ê°„ì€ ë¹¨ê°„ìƒ‰ì„ ìš°ì„ ìœ¼ë¡œ í•˜ê³ , ë‚˜ë¨¸ì§€ ì˜¤ë¥˜ ë¬¸ì¥ êµ¬ê°„ì€ íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    # 1. ëª¨ë“  ê²½ê³„ ì§€ì  ìˆ˜ì§‘ (0, ë, ê° ë§¤ì¹­ì˜ ì‹œì‘/ë)
    boundaries = {0, len(text)}
    for s, e in red_matches:
        boundaries.add(s)
        boundaries.add(e)
    for s, e in blue_matches:
        boundaries.add(s)
        boundaries.add(e)
    
    # ê²½ê³„ ì§€ì  ì •ë ¬
    sorted_boundaries = sorted(list(boundaries))
    
    final_html_parts = []
    
    # 2. ê° êµ¬ê°„ë³„ë¡œ ìŠ¤íƒ€ì¼ ì ìš© (Atomic Segments)
    for i in range(len(sorted_boundaries) - 1):
        start = sorted_boundaries[i]
        end = sorted_boundaries[i+1]
        segment_text = text[start:end]
        
        if not segment_text: continue
        
        # í˜„ì¬ êµ¬ê°„ì´ ë¹¨ê°„ìƒ‰ ë²”ìœ„ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        is_red = False
        for s, e in red_matches:
            if s <= start and end <= e:
                is_red = True
                break
        
        # í˜„ì¬ êµ¬ê°„ì´ íŒŒë€ìƒ‰ ë²”ìœ„ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        is_blue = False
        for s, e in blue_matches:
            if s <= start and end <= e:
                is_blue = True
                break
        
        escaped_text = html.escape(segment_text)
        
        if is_red:
            # ë¹¨ê°„ìƒ‰ê³¼ íŒŒë€ìƒ‰ì´ ê²¹ì¹˜ë©´ ë¹¨ê°„ìƒ‰ ìš°ì„ 
            final_html_parts.append(f'<span class="error-highlight">{escaped_text}</span>')
        elif is_blue:
            # íŒŒë€ìƒ‰ë§Œ ìˆëŠ” êµ¬ê°„
            final_html_parts.append(f'<span class="sentence-error-highlight">{escaped_text}</span>')
        else:
            # ì•„ë¬´ê²ƒë„ ì—†ëŠ” êµ¬ê°„
            final_html_parts.append(escaped_text)
            
    return "".join(final_html_parts)

def check_duplicate_sentences(text):
    """ì…€ ë‚´ ì¤‘ë³µ ë¬¸ì¥ì„ ê²€ì‚¬í•˜ê³ , ì¤‘ë³µëœ ë¬¸ì¥ì˜ (start, end) ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
    if not text or pd.isna(text):
        return False, "", []
        
    # ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œë¡œ ë¬¸ì¥ êµ¬ë¶„ (êµ¬ë¶„ìë„ í¬í•¨í•˜ì—¬ ìœ„ì¹˜ ì°¾ê¸°)
    sentence_matches = list(re.finditer(r'([^.!?]+[.!?])', text))
    
    # ì •ê·œì‹ìœ¼ë¡œ ë‚˜ëˆ ì§€ì§€ ì•ŠëŠ” ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    last_match_end = 0
    if sentence_matches:
        last_match_end = sentence_matches[-1].end()
        
    remaining_text = text[last_match_end:].strip()
    if remaining_text:
        # ë¬¸ì¥ìœ¼ë¡œ ì·¨ê¸‰í•  ìˆ˜ ìˆë„ë¡ ê°€ìƒì˜ (í…ìŠ¤íŠ¸, ì‹œì‘, ë) íŠœí”Œ ìƒì„±
        sentence_tuples = [(m.group(0).strip(), m.start(), m.end()) for m in sentence_matches]
        sentence_tuples.append((remaining_text, last_match_end, len(text)))
    else:
        sentence_tuples = [(m.group(0).strip(), m.start(), m.end()) for m in sentence_matches]

    clean_sentences = [s[0] for s in sentence_tuples if s[0]]

    if not clean_sentences or len(clean_sentences) < 2:
        return False, "", []

    sentence_counts = Counter(clean_sentences)
    dup_sentences_text = [s for s, c in sentence_counts.items() if c > 1]
    
    if not dup_sentences_text:
        return False, "", []
        
    matches = []
    # ì›ë³¸ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µëœ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ í•­ëª©ì˜ (start, end)ë¥¼ ì°¾ìŒ
    for s_text, start, end in sentence_tuples:
        if s_text in dup_sentences_text:
            matches.append((start, end))
    
    if not matches:
         return False, "", []

    return True, "ì¤‘ë³µ ë¬¸ì¥ ì¡´ì¬", matches

# --- Streamlit UI ---

def main():
    st.title("ğŸ« í•™êµìƒí™œê¸°ë¡ë¶€ íŠ¹ê¸°ì‚¬í•­ ê²€ì‚¬ê¸°")
    st.info("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ 'íŠ¹ê¸°ì‚¬í•­'ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ê²€ì‚¬í•©ë‹ˆë‹¤.")

    # ì˜¤ë¥˜ ê²€ì‚¬ í•­ëª© ì •ì˜ (ìœ í˜•, ì •ê·œì‹, ì˜¤ë¥˜ ë©”ì‹œì§€)
    ERROR_PATTERNS = [
        ("ë„ì–´ì“°ê¸° ë‘ë²ˆ", r'  +', "ë„ì–´ì“°ê¸° ë‘ë²ˆ"),
        ("íŠ¹ìˆ˜ ê¸°í˜¸", r'[!@#$%^&*_=+[\]{};\'":\\|<>/?~`()Â·]', "íŠ¹ìˆ˜ ê¸°í˜¸"),
        ("ì˜ì–´", r'[a-zA-Z]', "ì˜ì–´ í¬í•¨"),
        ("1ì¸ì¹­", r'\b(ë‚˜ì˜|ë‚˜ë§Œì˜|ë‚´( |ê°€|ëŠ”)|ì €ì˜|ì €ë§Œì˜|ì œ( |ê°€|ëŠ”))\b', "1ì¸ì¹­ í‘œí˜„"),
        ("ê³¼ê±°í˜•", r'(ì—ˆ|ì•˜|ì˜€)(ë‹¤|ìŠµë‹ˆë‹¤|ì–´ìš”|ìŒ)\b', "ê³¼ê±°í˜• ì¢…ê²° ì–´ë¯¸")
    ]

    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼(.xlsx, .xls)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx", "xls"])

    if uploaded_file:
        try:
            # í—¤ë” ì—†ì´ ì¼ë‹¨ ì½ì–´ì™€ì„œ íƒìƒ‰
            raw_df = pd.read_excel(uploaded_file, sheet_name=0, header=None)
            
            header_row_idx = None
            
            # [ìˆ˜ì •] 0ë²ˆ í–‰ë¶€í„° 19ë²ˆ í–‰ê¹Œì§€(ì—‘ì…€ 1í–‰~20í–‰) íƒìƒ‰ (ë²”ìœ„ í™•ëŒ€)
            for i in range(min(20, len(raw_df))):
                # í–‰ì˜ ê°’ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³ , ì¤„ë°”ê¿ˆ ë“±ì„ ì œê±°í•˜ì—¬ ê²€ì‚¬
                row_values = [str(val).replace('\n', ' ').replace('\r', '') for val in raw_df.iloc[i].values]
                if any("íŠ¹ê¸°ì‚¬í•­" in val for val in row_values):
                    header_row_idx = i
                    break
            
            if header_row_idx is None:
                st.error("ìƒìœ„ 20ê°œ í–‰ì—ì„œ 'íŠ¹ê¸°ì‚¬í•­'ì´ í¬í•¨ëœ í–‰(í—¤ë”)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return

            # ì°¾ì€ í–‰(header_row_idx)ì„ ì»¬ëŸ¼ ì´ë¦„ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
            sheet_df = raw_df.iloc[header_row_idx+1:].reset_index(drop=True)
            
            # [ìˆ˜ì •] ì»¬ëŸ¼ ì´ë¦„ ì •ì œ (ì¤„ë°”ê¿ˆ ì œê±° ë° ê³µë°± ì •ë¦¬)
            cleaned_columns = []
            for col in raw_df.iloc[header_row_idx]:
                col_str = str(col).replace('\n', ' ').replace('\r', '').strip()
                cleaned_columns.append(col_str)
            sheet_df.columns = cleaned_columns
            
            # ì—‘ì…€ì˜ ì‹¤ì œ í–‰ ë²ˆí˜¸ ê³„ì‚°ì„ ìœ„í•œ ì˜¤í”„ì…‹
            excel_row_offset = header_row_idx + 2 

            columns = list(sheet_df.columns)
            
            # 'íŠ¹ê¸°ì‚¬í•­'ì´ í¬í•¨ëœ ì»¬ëŸ¼ ìë™ ì„ íƒ
            selected_columns = [col for col in columns if "íŠ¹ê¸°ì‚¬í•­" in str(col)]
            
            if not selected_columns:
                st.error("í—¤ë” í–‰ì€ ì°¾ì•˜ìœ¼ë‚˜, 'íŠ¹ê¸°ì‚¬í•­' ì»¬ëŸ¼ì„ íŠ¹ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            else:
                st.success(f"ê²€ì‚¬ ëŒ€ìƒ: {', '.join(selected_columns)}")

            if st.button("ê²€ì‚¬ ì‹œì‘", type="primary"):
                # 'ì„±ëª…' ì»¬ëŸ¼ ìë™ ì°¾ê¸°
                id_column_name = None
                for col in columns:
                    if str(col) == "ì„±ëª…":
                        id_column_name = col
                        break

                with st.spinner("íŒŒì¼ì„ ê²€ì‚¬ ì¤‘ì…ë‹ˆë‹¤..."):
                    
                    if id_column_name:
                        st.success(f"í•™ìƒ '{id_column_name}'ì„ ì‹ë³„ìë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    else:
                        st.warning("'ì„±ëª…' ë°ì´í„°(ì—´)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²°ê³¼ì— í–‰ ë²ˆí˜¸ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
                        
                    # ì‹ë³„ì Series ìƒì„±
                    if id_column_name:
                        id_series = sheet_df[id_column_name].fillna("").astype(str)
                    else:
                        # í–‰ ë²ˆí˜¸ ê³„ì‚° ì‹œ ì˜¤í”„ì…‹ ì ìš©
                        id_series = sheet_df.index.to_series().apply(lambda x: f"{x + excel_row_offset}ë²ˆ í–‰")

                    # 'ì»¬ëŸ¼ ë‚´ ì¤‘ë³µ ì…€' ê²€ì‚¬ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
                    duplicate_masks = {}
                    duplicate_partners_map = {}
                    
                    for col_name in selected_columns:
                        all_texts = sheet_df[col_name].fillna("").astype(str)
                        # ì¤‘ë³µ ë§ˆìŠ¤í¬
                        duplicate_masks[col_name] = all_texts.duplicated(keep=False) & (all_texts != "")
                        
                        # ì¤‘ë³µ ëŒ€ìƒ ë§¤í•‘
                        grouped = sheet_df.groupby(all_texts)
                        col_key = col_name 
                        duplicate_partners_map[col_key] = {}
                        
                        for text_content, group in grouped:
                            if text_content == "" or len(group) < 2:
                                continue
                            
                            partners = id_series.loc[group.index].tolist()
                            for index in group.index:
                                current_id = id_series.loc[index]
                                other_partners = [p for p in partners if p != current_id]
                                duplicate_partners_map[col_key][index] = other_partners

                    results = []

                    # ëª¨ë“  í–‰ ìˆœíšŒ
                    for index, row in sheet_df.iterrows():
                        for col_name in selected_columns:
                            text = str(row[col_name]) if pd.notna(row[col_name]) else ""
                            if not text.strip():
                                continue

                            errors_found = []
                            red_matches = []  # ë‹¨ì–´ ì˜¤ë¥˜ (ë¹¨ê°•)
                            blue_matches = [] # ë¬¸ì¥/ì…€ ì˜¤ë¥˜ (íŒŒë‘)
                            
                            # 1. ì •ê·œì‹ ì˜¤ë¥˜ (ë¹¨ê°•)
                            red_matches, regex_errors = find_regex_errors(text, ERROR_PATTERNS)
                            errors_found.extend(regex_errors)

                            # 2. ì…€ ë‚´ ì¤‘ë³µ ë¬¸ì¥ (íŒŒë‘)
                            has_dup_sentence, dup_sentence_msg, sentence_blue_matches = check_duplicate_sentences(text)
                            if has_dup_sentence:
                                errors_found.append(dup_sentence_msg)
                                blue_matches.extend(sentence_blue_matches)

                            # 3. ì»¬ëŸ¼ ë‚´ ì¤‘ë³µ ì…€ (íŒŒë‘)
                            is_dup_cell = duplicate_masks[col_name][index]
                            if is_dup_cell:
                                col_key = col_name
                                partners = duplicate_partners_map.get(col_key, {}).get(index, [])
                                partner_string = ", ".join(partners) if partners else "ì•Œ ìˆ˜ ì—†ìŒ"
                                errors_found.append(f"'{col_name}' ì „ì²´ ë‚´ìš© ì¤‘ë³µ (ì¤‘ë³µ ëŒ€ìƒ: {partner_string})")
                                
                                # ì „ì²´ ì¤‘ë³µì´ë©´ì„œ, ë¬¸ì¥ ì¤‘ë³µì´ ì•„ë‹ ë•Œë§Œ ì „ì²´ë¥¼ íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                                if not has_dup_sentence:
                                    blue_matches.append((0, len(text)))

                            # ê²°ê³¼ ì €ì¥
                            if errors_found:
                                id_value = ""
                                if id_column_name and id_column_name in row:
                                    id_value = str(row[id_column_name]) if pd.notna(row[id_column_name]) else ""
                                
                                # í•˜ì´ë¼ì´íŠ¸ ì ìš©
                                final_highlighted_text = apply_merged_highlights(text, red_matches, blue_matches)
                                
                                # í–‰ ë²ˆí˜¸ ì €ì¥ ì‹œ ì˜¤í”„ì…‹ ì ìš©
                                results.append({
                                    "index": index + excel_row_offset,
                                    "id_value": id_value,
                                    "column": col_name,
                                    "original_text": text,
                                    "highlighted_text": final_highlighted_text,
                                    "errors": list(set(errors_found)),
                                })

                st.success(f"ê²€ì‚¬ ì™„ë£Œ! ì´ {len(sheet_df)}ëª…, íŠ¹ê¸°ì‚¬í•­ ê²€ì‚¬ ê²°ê³¼ {len(results)}ê°œì˜ ìˆ˜ì • ê¶Œì¥ ì‚¬í•­ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

                if results:
                    st.markdown("---")
                    st.subheader("ê²€ì‚¬ ê²°ê³¼ ìƒì„¸")
                    
                    for res in results:
                        id_display_string = f"({res['id_value']}) " if res['id_value'] else ""
                        st.markdown(f"**ğŸ“Œ {res['index']}ë²ˆ í–‰ {id_display_string}, '{res['column']}' ì»¬ëŸ¼**")
                        st.markdown(f"> {res['highlighted_text']}", unsafe_allow_html=True)
                        
                        if res['errors']:
                            # ì˜¤ë¥˜ ë‚´ìš© ê°„ê²©ì„ ë„“ê²Œ ì¡°ì • (ì‰¼í‘œ + ê³µë°± 4ì¹¸)
                            formatted_errors = ',    '.join(res['errors'])
                            st.error(f"**[ë°œê²¬ëœ ì˜¤ë¥˜]** {formatted_errors}")
                        st.markdown("---")
                else:
                    st.balloons()
                    st.success("ëª¨ë“  í•­ëª©ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë°œê²¬ëœ ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤! ğŸ‰")

        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ê±°ë‚˜ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()